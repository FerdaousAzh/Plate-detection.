{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95f89902",
   "metadata": {},
   "source": [
    "# Moroccan plates detection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7b2832",
   "metadata": {},
   "source": [
    "# Participants:\n",
    "Abderrahman Skiredj & Ferdaous Azhari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852150e6",
   "metadata": {},
   "source": [
    "# Project goal:\n",
    "Automatic identification of the license plate string of the car(s) in a given image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b9b1c7",
   "metadata": {},
   "source": [
    "## Pipeline :\n",
    "### Step 0 (optional, used only if step 1 didnt succeed): Vehicle detection\n",
    "Read the image then detect the sub-images corresponding to vehicles\n",
    "### Step 1: Plate detection\n",
    "Read the image then detect its sub-images corresponding to the plates\n",
    "### Step 2: Characters detection\n",
    "For each subimage correspondig to a plate, segment it in its turn to subimages corresponding to characters\n",
    "### Step 3: Pate string recognition\n",
    "For each sub-image corresponding to a character, recognize the character written in it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659ad480",
   "metadata": {},
   "source": [
    "# Existing open source projects\n",
    "we have leveraged the following existing projects https://github.com/HamzaEzzRa/MLPDR (for step 1 , 2 and 3), the project https://techvidvan.com/tutorials/opencv-vehicle-detection-classification-counting/ (for step 0)\n",
    "\n",
    "# Limitations of leveraged projects and proposed solutions\n",
    "- the project https://github.com/HamzaEzzRa/MLPDR cant detect plates of cars that are far away in the image. In this case we enhance it with the aforementioned step 0\n",
    "- It didnt succeed detecting plates with black background (they are those plates with the letter \"m\" or \"almaghrib\" typically for dacia duster car). The solution is to detect such a case, deduce that the letter character is red (it's always the case) and is either \"m\" or \"jim\",  invert the image (take its negative) to retrieve the digits\n",
    "- For plates that are not well contrasted/brighted, the characters couldnt be identified. The proposed solution is to loop on many possible brightness values and contrast values then modify the image according to these values then predict the plates and finally take the prediction with highest confidence\n",
    "- Finally the project couldnt predict correctly when plates are of squared forms (with 2 lines of characters). Our idea was to detect such cases (it is easy as the detected characters have overlapping x axis), then take the characters of the second line first then the characters of the first line. We couldnt implement the idea in the allotted time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838bdab0",
   "metadata": {},
   "source": [
    "# The code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca5f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install requirements\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8091443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements_str='''\n",
    "arabic-reshaper==2.1.3\n",
    "cycler==0.10.0\n",
    "decorator==4.4.2\n",
    "future==0.18.2\n",
    "imageio==2.9.0\n",
    "imutils==0.5.4\n",
    "kiwisolver==1.3.1\n",
    "matplotlib==3.4.1\n",
    "networkx==2.5.1\n",
    "numpy==1.20.2\n",
    "opencv-contrib-python==4.5.1.48\n",
    "opencv-python==4.5.2.52\n",
    "Pillow==8.2.0\n",
    "pyparsing==2.4.7\n",
    "PyQt5==5.15.4\n",
    "PyQt5-Qt5==5.15.2\n",
    "PyQt5-sip==12.9.0\n",
    "pytesseract==0.3.7\n",
    "python-bidi==0.4.2\n",
    "python-dateutil==2.8.1\n",
    "PyWavelets==1.1.1\n",
    "scikit-image==0.18.1\n",
    "scipy==1.6.3\n",
    "six==1.15.0\n",
    "tifffile==2021.4.8'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c68fc2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "!pip install arabic-reshaper==2.1.3\n",
      "!pip install cycler==0.10.0\n",
      "!pip install decorator==4.4.2\n",
      "!pip install future==0.18.2\n",
      "!pip install imageio==2.9.0\n",
      "!pip install imutils==0.5.4\n",
      "!pip install kiwisolver==1.3.1\n",
      "!pip install matplotlib==3.4.1\n",
      "!pip install networkx==2.5.1\n",
      "!pip install numpy==1.20.2\n",
      "!pip install opencv-contrib-python==4.5.1.48\n",
      "!pip install opencv-python==4.5.2.52\n",
      "!pip install Pillow==8.2.0\n",
      "!pip install pyparsing==2.4.7\n",
      "!pip install PyQt5==5.15.4\n",
      "!pip install PyQt5-Qt5==5.15.2\n",
      "!pip install PyQt5-sip==12.9.0\n",
      "!pip install pytesseract==0.3.7\n",
      "!pip install python-bidi==0.4.2\n",
      "!pip install python-dateutil==2.8.1\n",
      "!pip install PyWavelets==1.1.1\n",
      "!pip install scikit-image==0.18.1\n",
      "!pip install scipy==1.6.3\n",
      "!pip install six==1.15.0\n",
      "!pip install tifffile==2021.4.8\n"
     ]
    }
   ],
   "source": [
    "print(requirements_str.replace('\\n','\\n!pip install '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b799ce81",
   "metadata": {},
   "source": [
    "# Helper functions for step 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997dd4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tracker import *\n",
    "\n",
    "# Initialize Tracker\n",
    "tracker = EuclideanDistTracker()\n",
    "\n",
    "input_size = 320\n",
    "\n",
    "# Detection confidence threshold\n",
    "confThreshold = 0.2\n",
    "nmsThreshold = 0.2\n",
    "\n",
    "font_color = (0, 0, 255)\n",
    "font_size = 0.5\n",
    "font_thickness = 2\n",
    "\n",
    "# Middle cross line position\n",
    "middle_line_position = 225\n",
    "up_line_position = middle_line_position - 15\n",
    "down_line_position = middle_line_position + 15\n",
    "\n",
    "# Store Coco Names in a list\n",
    "classesFile = \"coco.names\"\n",
    "classNames = open(classesFile).read().strip().split('\\n')\n",
    "\n",
    "# class index for our required detection classes\n",
    "required_class_index = [2,3,7]\n",
    "\n",
    "detected_classNames = []\n",
    "\n",
    "## Model Files\n",
    "modelConfiguration = 'yolov3-320.cfg'\n",
    "modelWeigheights = 'yolov3-320.weights'\n",
    "\n",
    "# configure the network model\n",
    "net = cv2.dnn.readNetFromDarknet(modelConfiguration, modelWeigheights)\n",
    "\n",
    "# Configure the network backend\n",
    "\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "# Define random colour for each class\n",
    "np.random.seed(42)\n",
    "colors = np.random.randint(0, 255, size=(len(classNames), 3), dtype='uint8')\n",
    "\n",
    "\n",
    "# Function for finding the center of a rectangle\n",
    "def find_center(x, y, w, h):\n",
    "    x1 = int(w / 2)\n",
    "    y1 = int(h / 2)\n",
    "    cx = x + x1\n",
    "    cy = y + y1\n",
    "    return cx, cy\n",
    "\n",
    "\n",
    "# List for store vehicle count information\n",
    "temp_up_list = []\n",
    "temp_down_list = []\n",
    "up_list = [0, 0, 0, 0]\n",
    "down_list = [0, 0, 0, 0]\n",
    "\n",
    "\n",
    "# Function for finding the detected objects from the network output\n",
    "def postProcess(outputs, img, img_path):\n",
    "    global detected_classNames\n",
    "    height, width = img.shape[:2]\n",
    "    boxes = []\n",
    "    classIds = []\n",
    "    confidence_scores = []\n",
    "    detection = []\n",
    "    for output in outputs:\n",
    "        for det in output:\n",
    "            scores = det[5:]\n",
    "            classId = np.argmax(scores)\n",
    "            confidence = scores[classId]\n",
    "            if classId in required_class_index:\n",
    "                if confidence > confThreshold:\n",
    "                    # print(classId)\n",
    "                    w, h = int(det[2] * width), int(det[3] * height)\n",
    "                    x, y = int((det[0] * width) - w / 2), int((det[1] * height) - h / 2)\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    classIds.append(classId)\n",
    "                    confidence_scores.append(float(confidence))\n",
    "\n",
    "    # Apply Non-Max Suppression\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidence_scores, confThreshold, nmsThreshold)\n",
    "    # print(classIds)\n",
    "    if np.size(indices) > 0:\n",
    "        for i in indices.flatten():\n",
    "            x, y, w, h = boxes[i][0], boxes[i][1], boxes[i][2], boxes[i][3]\n",
    "\n",
    "            name = classNames[classIds[i]]\n",
    "            detected_classNames.append(name)\n",
    "            detection.append([x, y, w, h, required_class_index.index(classIds[i])])\n",
    "\n",
    "\n",
    "    images = [img[z[1]: z[1]+z[3], z[0]: z[0]+z[2]] for z in detection]\n",
    "    return images\n",
    "\n",
    "\n",
    "\n",
    "def from_static_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(img, 1 / 255, (input_size, input_size), [0, 0, 0], 1, crop=False)\n",
    "\n",
    "    # Set the input of the network\n",
    "    net.setInput(blob)\n",
    "    layersNames = net.getLayerNames()\n",
    "    outputNames = [(layersNames[i[0] - 1]) for i in net.getUnconnectedOutLayers()]\n",
    "    # Feed data to the network\n",
    "    outputs = net.forward(outputNames)\n",
    "\n",
    "    # Find the objects from the network output\n",
    "    return postProcess(outputs, img, img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f915684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef06f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dba69f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7635d416",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
